{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "module_rootdir = '.'\n",
    "dataset_rootdir = '../'\n",
    "label_rootdir = module_rootdir\n",
    "weight_rootdir = module_rootdir\n",
    "sys.path.append(module_rootdir)\n",
    "\n",
    "DET_DIR = 'mAP/input/detection-results'\n",
    "GT_DIR = 'mAP/input/ground-truth'\n",
    "\n",
    "from modules.proposal.box_association import  identify_prominent_objects\n",
    "from modules.first_stage.inference import inference\n",
    "from modules.first_stage.set_parameters_for_inference import set_param_for_inference\n",
    "from modules.plot.viz_annotation import vizualize_bbox_resized\n",
    "from modules.dataset_utils.kitti_dataset_utils.constants import _IDX_TO_OBJ_CLASS_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available. Good to go!\n",
      "printing model config parameters\n",
      "----------------------------------------------------------------------------------------------------\n",
      "backbone                        : efficientnet_b4\n",
      "num_backbone_nodes              : 4\n",
      "num_extra_blocks                : 1\n",
      "num_levels                      : 5\n",
      "extra_blocks_feat_dim           : 512\n",
      "num_fpn_blocks                  : 2\n",
      "fpn_feat_dim                    : 128\n",
      "prediction head stem_channels   : [128, 128, 128, 128]\n",
      "activation                      : swish\n",
      "image dimension BDD (H, W, D)   : (360, 640, 3)\n",
      "image dimension KITTI (H, W, D) : (263, 873, 3)\n",
      "num_classes                     : 2\n",
      "DEVICE                          : cuda\n",
      "****************************************************************************************************\n",
      " \n",
      "Loading JSON file .. please wait\n",
      "Sequence: 0000\n",
      "Sequence: 0001\n",
      "Sequence: 0002\n",
      "Sequence: 0003\n",
      "Sequence: 0004\n",
      "Sequence: 0005\n",
      "Sequence: 0006\n",
      "Sequence: 0008\n",
      "Sequence: 0009\n",
      "Sequence: 0011\n",
      "Sequence: 0012\n",
      "Sequence: 0015\n",
      "Sequence: 0016\n",
      "Sequence: 0017\n",
      "Sequence: 0019\n",
      "Sequence: 0020\n",
      "Loading JSON file .. please wait\n",
      "Sequence: 0007\n",
      "Sequence: 0010\n",
      "Sequence: 0013\n",
      "Sequence: 0014\n",
      "Sequence: 0018\n"
     ]
    }
   ],
   "source": [
    "weights_file = 'model_weights/1705990924432/anchor_free_detector.pt'\n",
    "\n",
    "param_dict = set_param_for_inference(\n",
    "    dataset_type = 'kitti',\n",
    "    module_rootdir = module_rootdir,\n",
    "    dataset_rootdir = dataset_rootdir,\n",
    "    label_rootdir = label_rootdir,\n",
    "    batch_size = 1,\n",
    "    trained_weights_file = os.path.join(weight_rootdir, weights_file))\n",
    "\n",
    "device = param_dict['device']\n",
    "dataset_param = param_dict['dataset_param']\n",
    "dataset_train = param_dict['dataset_train']\n",
    "dataset_val = param_dict['dataset_val'] \n",
    "detector = param_dict['detector']\n",
    "\n",
    "deltas_mean = torch.tensor(dataset_param.deltas_mean, dtype=torch.float32, device=device)\n",
    "deltas_std = torch.tensor(dataset_param.deltas_std, dtype=torch.float32, device=device)\n",
    "grid_coord = dataset_param.grid_coord.to(device)\n",
    "ignored_classId = dataset_param.ignored_classId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1879/1879 [02:11<00:00, 14.26it/s]\n"
     ]
    }
   ],
   "source": [
    "det_dir = os.path.join(module_rootdir, DET_DIR)\n",
    "gt_dir = os.path.join(module_rootdir, GT_DIR)\n",
    "\n",
    "if not os.path.exists(det_dir): \n",
    "    os.makedirs(det_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(gt_dir): \n",
    "    os.makedirs(gt_dir, exist_ok=True)\n",
    "\n",
    "# dataset = dataset_train\n",
    "dataset = dataset_val\n",
    "iter_start_offset = 0\n",
    "max_iters = iter_start_offset + len(dataset)\n",
    "\n",
    "nms_thresh = 0.35\n",
    "# score_threshold = torch.tensor([0.5, 0.4], dtype=torch.float32).to(device)\n",
    "# score_threshold = torch.tensor([0.6, 0.5], dtype=torch.float32).to(device)\n",
    "# score_threshold = torch.tensor([0.7, 0.6], dtype=torch.float32).to(device)\n",
    "score_threshold = torch.tensor([0.8, 0.7], dtype=torch.float32).to(device)\n",
    "\n",
    "for iter in tqdm(range(iter_start_offset, max_iters)):\n",
    "\n",
    "    img, labels = dataset.__getitem__(iter)\n",
    "    img_path = labels['img_path']\n",
    "    img = img.unsqueeze(0).to(device)\n",
    "    bboxes = labels['bbox'].to(device)\n",
    "    clslabels = labels['obj_class_label'].to(device)\n",
    "\n",
    "    valid_gt_objects_flag = identify_prominent_objects(bboxes) & (clslabels != ignored_classId) \n",
    "    bboxes = bboxes[valid_gt_objects_flag]\n",
    "    clslabels = clslabels[valid_gt_objects_flag]\n",
    "\n",
    "    pred = inference(\n",
    "        detector, img, grid_coord, \n",
    "        deltas_mean, deltas_std,\n",
    "        score_threshold, nms_thresh)\n",
    "    \n",
    "    pred_score = pred['pred_score'].cpu().numpy()\n",
    "    pred_class = pred['pred_class'].cpu().numpy()\n",
    "    pred_box = pred['pred_box'].cpu().numpy()\n",
    "    gt_class = clslabels.cpu().numpy()\n",
    "    gt_box = bboxes.cpu().numpy()\n",
    "    gt_class = [_IDX_TO_OBJ_CLASS_[int(i)] for i in gt_class]\n",
    "    pred_class = [_IDX_TO_OBJ_CLASS_[int(i)] for i in pred_class]\n",
    "\n",
    "    # Skip current iteration if no predictions were found.\n",
    "    if pred_box.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    file_name = str(iter) + '.txt'\n",
    "\n",
    "    with open(os.path.join(det_dir, file_name), \"w\") as file_det: \n",
    "          for label, box, conf in zip(pred_class, pred_box, pred_score):\n",
    "                line = f\"{label} {conf:.6f} {box[0]:.2f} {box[1]:.2f} {box[2]:.2f} {box[3]:.2f}\\n\"\n",
    "                file_det.write(line)\n",
    "\n",
    "    with open(os.path.join(gt_dir, file_name), \"w\") as file_gt: \n",
    "          for label, box in zip(gt_class, gt_box):\n",
    "                line = f\"{label} {box[0]:.2f} {box[1]:.2f} {box[2]:.2f} {box[3]:.2f}\\n\"\n",
    "                file_gt.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.50% = person AP \n",
      "79.50% = vehicle AP \n",
      "mAP = 69.50%\n"
     ]
    }
   ],
   "source": [
    "%run ./mAP/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
